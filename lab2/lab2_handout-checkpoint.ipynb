{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ad26da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Lab 2 <br><br> Gradient descent and <br> Stochastic Gradient Descent </center></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b950901d",
   "metadata": {},
   "source": [
    "Note: The format for the report is as a Jupyter Notebook. Please include the section number and SIDs of the members of your group in the results dictionary. A single notebook should be submitted as a group submission in Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    'section_number' : 0, # enter your student id here\n",
    "    'SIDs': [0,0] # enter the SIDs for the group members\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7366e6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf83570",
   "metadata": {},
   "source": [
    "In this lab we will explore the gradient descent and stochastic gradient descent algorithms for solving a least squares optimization problem. The setup is as follows. We wish to model a process with scalar input $X$ and scalar output $Y$. Both of these are real-valued random variables; their sample spaces are the real line. The joint distribution of $X$ and $Y$ is given as:\n",
    "\\begin{align*}\n",
    "X &\\sim \\mathcal{U}(0,1) \\\\\n",
    "Y|X\\!=\\!x &\\sim \\mathcal{N}( \\theta_0 + \\theta_1 x ,\\sigma^2_\\epsilon)\n",
    "\\end{align*}\n",
    "This definition of $Y|X\\!=\\!x$ is equivalent to,\n",
    "\\begin{equation*}\n",
    "Y = \\theta_0 + \\theta_1 X + \\epsilon\n",
    "\\end{equation*}\n",
    "with $\\epsilon\\sim\\mathcal{N}(0,\\sigma^2_\\epsilon)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd43a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edcb6d4",
   "metadata": {},
   "source": [
    "# 1. Sampling the joint distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753ef4b",
   "metadata": {},
   "source": [
    "We will first construct a synthetic dataset by sampling  from $(X,Y)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3aff5",
   "metadata": {},
   "source": [
    "## (1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d27b6",
   "metadata": {},
   "source": [
    "Write a function called `sampleXY` that produces a dataset $\\{(x_n,y_n)\\}_N$ of iid samples from $(X,Y)$, given arguments $N$, $\\theta_0$, $\\theta_1$, and $\\sigma^2_\\epsilon$. The output of this function should be a numpy array with shape = $(N,2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ed7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleXY(N, theta0, theta1, sigma2_eps):\n",
    "    samples = np.empty((N,2))\n",
    "    x = stats.uniform.rvs(loc = 0, scale = 1, size=N)\n",
    "    eps = stats.norm.rvs(size=N, loc = 0, scale = np.sqrt(sigma2_eps))\n",
    "    y = theta0 + theta1*x + eps\n",
    "    X = np.array(x)\n",
    "    Y = np.array(y)\n",
    "    samples = np.c_[X,Y]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb9e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8031286  -0.2638138 ]\n",
      " [ 0.64279026  0.02360547]\n",
      " [ 0.10105385  0.09596306]\n",
      " [ 0.27451179  0.15862839]\n",
      " [ 0.91731549 -0.14083791]\n",
      " [ 0.69867603 -0.08490476]\n",
      " [ 0.08825954  0.10498608]\n",
      " [ 0.57893565 -0.07919184]\n",
      " [ 0.362736    0.00958359]\n",
      " [ 0.62544761  0.1042921 ]\n",
      " [ 0.10215369  0.06705512]\n",
      " [ 0.70127475 -0.08047269]\n",
      " [ 0.14009893  0.15068465]\n",
      " [ 0.29365748  0.0851756 ]\n",
      " [ 0.62467869 -0.10008379]\n",
      " [ 0.41207258 -0.00841087]\n",
      " [ 0.23966896  0.17152868]\n",
      " [ 0.25014681  0.19048052]\n",
      " [ 0.22156411  0.20945322]\n",
      " [ 0.0752091   0.28873129]\n",
      " [ 0.4121294   0.1241299 ]\n",
      " [ 0.44284106  0.07116373]\n",
      " [ 0.48108999  0.05383617]\n",
      " [ 0.71157291 -0.07246109]\n",
      " [ 0.32435379  0.09968427]\n",
      " [ 0.94118485 -0.19152656]\n",
      " [ 0.95886772 -0.14180071]\n",
      " [ 0.6485036  -0.06165199]\n",
      " [ 0.65380404  0.00878572]\n",
      " [ 0.91110008 -0.37401157]\n",
      " [ 0.16197987  0.17845698]\n",
      " [ 0.65718228 -0.19219067]\n",
      " [ 0.87466191 -0.09705835]\n",
      " [ 0.25544464  0.12740693]\n",
      " [ 0.91189036  0.01756089]\n",
      " [ 0.22023426  0.20488892]\n",
      " [ 0.69178324 -0.06398053]\n",
      " [ 0.58719498 -0.04541761]\n",
      " [ 0.12502244  0.16104705]\n",
      " [ 0.81754612 -0.16118594]]\n"
     ]
    }
   ],
   "source": [
    "N = 40\n",
    "theta0=0.2\n",
    "theta1=-0.4\n",
    "sigma2_eps=0.0049\n",
    "XYsamp = sampleXY(N, theta0, theta1, sigma2_eps)\n",
    "print(XYsamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c49f8",
   "metadata": {},
   "source": [
    "Run `sampleXY` with $N\\!=\\!40$, $\\theta_0\\!=\\!0.2$, $\\theta_1\\!=\\!-0.4$, and $\\sigma^2_\\epsilon\\!=\\!0.0049$ and assign the result to the variable `XYsamp`. Create a plot showing the line $y=\\theta_0 + \\theta_1 x$, overlaid with a scatter plot of `XYsamp`. The plot should have labels on the x and y axes. (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af952ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x19cbc8c03d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure()\n",
    "x = XYsamp[:,0]\n",
    "y = XYsamp[:,1]\n",
    "plt.scatter(x,y)\n",
    "yver = theta0 + theta1*x\n",
    "plt.plot(x,yver, 'g')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend(['Samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ce29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig1'] = fig1\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314585ca",
   "metadata": {},
   "source": [
    "We will now overwrite the data you sampled with another dataset contained in the file `1d_data.pickle`. This is so the results are predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4782fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./1d_data.pickle', 'rb') as file:\n",
    "    XYsamp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c4147",
   "metadata": {},
   "source": [
    "# 2. Least squares linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36327370",
   "metadata": {},
   "source": [
    "We will now produce estimates of $\\theta_0$ and $\\theta_1$ corresponding to the least squares estimate of a straigt line fitted to `XYsamp`. The model in this case is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat y(x) = h(x;\\hat\\theta_0,\\hat\\theta_1) =  \\hat\\theta_0 +  \\hat\\theta_1 x\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The error for each sample is the squared difference between the sampled and modeled values:\n",
    "\\begin{equation*}\n",
    "\\ell_n(\\hat\\theta_0,\\hat\\theta_1) = \\left( \\hat y(x_n) - y_n \\right)^2 = (\\hat \\theta_0 + \\hat \\theta_1 \\: x_n - y_n)^2 \n",
    "\\end{equation*}\n",
    "\n",
    "Notice a slightly confusing but crucial point: We are considering the error for the $n$'th sample ($\\ell_n$) as a function of the parameter estimates $\\hat\\theta_0$ and $\\hat\\theta_1$, with \"parameters\" $x_n$ and $y_n$, whereas the model $h$ is a function of $x$ with parameters $\\hat\\theta_0$ and $\\hat\\theta_1$. The roles of \"input\" and \"parameter\" are inverted. \n",
    "\n",
    "We define the matrix $\\Phi\\in\\mathbb{R}^{N\\times 2}$ such that the model can be written in matrix form:\n",
    "\\begin{equation*}\n",
    "\\mathbf{\\hat Y} = \\Phi \\: \\hat\\theta \n",
    "\\end{equation*}\n",
    "where \n",
    "\\begin{equation*}\n",
    "\\hat\\theta = \\begin{bmatrix}\\hat\\theta_0 \\\\ \\hat\\theta_1 \\end{bmatrix} \\hspace{3em} \\text{and} \\hspace{3em}\n",
    "\\mathbf{\\hat Y} = \\begin{bmatrix} \\hat y(x_1) \\\\ \\vdots \\\\ \\hat y(x_N) \\end{bmatrix} \n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "The total loss for candidate parameters $\\hat\\theta_0$ and $\\hat\\theta_1$ is defined as the sum of the losses for each sample:\n",
    "\\begin{equation*}\n",
    "L(\\hat\\theta_0, \\hat\\theta_1) \\;=\\; \\sum_{n=1}^{N} \\ell_n(\\hat\\theta_0, \\hat\\theta_1) \\;=\\; \\sum_{n=1}^{N} \\left( \\hat y(x_n) - y_n \\right)^2 \\;=\\; \\lvert\\lvert \\Phi \\hat\\theta-\\mathbf{Y} \\rvert\\rvert^2_2\n",
    "\\end{equation*}\n",
    "\n",
    "Thus the problem of finding the least squares estimates of $\\theta_0$ and $\\theta_1$ can be written as:\n",
    "\\begin{align*}\n",
    "&\\underset{\\hat\\theta_0,\\: \\hat\\theta_1}{\\text{minimize}} \\: L(\\hat\\theta_0, \\hat\\theta_1) \\\\\n",
    "\\equiv \\quad\n",
    "&\\underset{\\hat\\theta_0,\\: \\hat\\theta_1}{\\text{minimize}} \\:\n",
    "\\sum_{n=1}^{N} \\ell_n(\\hat\\theta_0, \\hat\\theta_1)\n",
    "\\\\\n",
    "\\equiv \\quad\n",
    "&\\underset{\\hat\\theta_0, \\:\\hat\\theta_1}{\\text{minimize}} \\: \\sum_{n=1}^{N} \\left( \\hat\\theta_0 + \\hat \\theta_1 \\:x_n - y_n \\right)^2 \\\\\n",
    "\\equiv \\quad\n",
    "&\\underset{\\hat\\theta}{\\text{minimize}} \\: \\lvert\\lvert \\Phi \\hat\\theta-\\mathbf{Y} \\rvert\\rvert^2_2\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89e479",
   "metadata": {},
   "source": [
    "## (2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4d58dd",
   "metadata": {},
   "source": [
    "Write a function called `solve_lr` that takes `XYsamp` as input, constructs $\\Phi$ and $\\mathbf{Y}$, and finds the exact solution to the least squares problem using the formula,\n",
    "\\begin{equation*}\n",
    "\\hat\\theta = (\\Phi^T \\Phi)^{-1}\\Phi^T \\mathbf{Y}\n",
    "\\end{equation*}\n",
    "This function should return the solution as a numpy array of length 2 with $\\hat\\theta_0$ in the zeroth position and $\\hat\\theta_1$ in the first position. (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def solve_lr(XYsamp):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "# result['theta_2a'] = solve_lr(XYsamp)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a600bc",
   "metadata": {},
   "source": [
    "# 3. Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f85d16",
   "metadata": {},
   "source": [
    "We will now write an iterative numerical algorithm for solving the least squares problem. We take the objective function of the problem to be:\n",
    "\\begin{equation*}\n",
    "J(\\hat\\theta_0,\\hat\\theta_1) = \\sum_{n=1}^{N} \\left( \\hat\\theta_0 + \\hat \\theta_1 \\:x_n - y_n \\right)^2\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b9597",
   "metadata": {},
   "source": [
    "## (3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940417a",
   "metadata": {},
   "source": [
    "Write a function called `nablaJ` that takes `XYsamp`, $\\hat\\theta_0$, and $\\hat\\theta_1$ as inputs, and returns the gradient as a numpy array of length 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72128258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nablaJ(XYsamp, theta0, theta1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db39e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['nablaJ_3a_a'] = nablaJ(XYsamp,0.5,-1)\n",
    "result['nablaJ_3a_b'] = nablaJ(XYsamp,1.1,0.6)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecce757",
   "metadata": {},
   "source": [
    "## (3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f6380",
   "metadata": {},
   "source": [
    "Write a function called `gradient_descent` that executes the gradient descent algorithm. This function should take as input \n",
    "\n",
    "+ The dataset `XYsamp`\n",
    "+ the total number of steps to take $K$\n",
    "+ the step size $\\gamma$\n",
    "+ the initial condition Theta0 as a numpy array of length 2. \n",
    "\n",
    "It should return the trajectory as a with shape = `(K,2)`. (8 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5537afb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_gd_on_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trajectories\u001b[38;5;241m=\u001b[39m\u001b[43mrun_gd_on_grid\u001b[49m(theta0_grid,theta1_grid,\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_descent\u001b[39m(XYsamp,K,gamma,Theta0):\n\u001b[0;32m      4\u001b[0m     Theta_trajec\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mlist\u001b[39m(Theta0)]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_gd_on_grid' is not defined"
     ]
    }
   ],
   "source": [
    "trajectories=run_gd_on_grid(theta0_grid,theta1_grid,200,0.2)\n",
    "\n",
    "def gradient_descent(XYsamp,K,gamma,Theta0):\n",
    "    Theta_trajec=[list(Theta0)]\n",
    "    for i in range(K):\n",
    "        print(Theta_trajec)\n",
    "        d_Theta = list(-gamma * nablaJ(XYsamp, Theta_trajec[-1][0], Theta_trajec[-1][1]))  #calcule le vecteur pour aller au prochain point\n",
    "        print(nablaJ)\n",
    "        print(d_Theta)\n",
    "        Theta_trajec += [Theta_trajec[-1][0] + d_Theta[0], #ajoute ce vecteur au point actuel pour arriver au prochain point\n",
    "                         Theta_trajec[-1][1] + d_Theta[1]]\n",
    "    return np.array(Theta_trajec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['gd_3b_a'] = gradient_descent(XYsamp,10,0.1,np.array([-0.5,0.5]))\n",
    "result['gd_3b_b'] = gradient_descent(XYsamp,20,0.01,np.array([0.5,-0.5]))\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07150daa",
   "metadata": {},
   "source": [
    "## (3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07442e5f",
   "metadata": {},
   "source": [
    "Complete the `run_gd_on_grid(theta0_grid,theta1_grid,K,gamma)`. This function takes as input\n",
    "+ `theta0_grid` and `theta1_grid`. These are a 5x5 grid of values of $\\hat\\theta_0$ and $\\hat\\theta_1$. \n",
    "+ `K`: the number of steps to take, and\n",
    "+ `gamma`: the step size. \n",
    "\n",
    "The function should return a numpy array with shape (5,5,K,2), where the (i,j,:,:) is a (K,2) trajectory of parameter values. \n",
    "\n",
    "Run the function with $K=200$, $\\gamma=0.2$ and save the result to `trajectories`.\n",
    "\n",
    "Note: The code for creating the 5x5 grid is provided. \n",
    "\n",
    "(8 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5944e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not alter this code. It creates the 5x5 grid of values \n",
    "# that are passed to `run_gd_on_grid`\n",
    "def make_grid(gridN):\n",
    "    theta_0_array = np.linspace(-1,1,gridN)\n",
    "    theta_1_array = np.linspace(-1,1,gridN)\n",
    "    return  np.meshgrid(theta_0_array,theta_1_array)\n",
    "\n",
    "gridN = 5\n",
    "theta0_grid,theta1_grid = make_grid(gridN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af14c144",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (971271748.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [3]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Theta0=[theta0,theta1]\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def run_gd_on_grid(theta0_grid,theta1_grid,K,gamma):\n",
    "    trajectories=[]\n",
    "    for theta0 in theta0_grid:  #pour chaque combinaison entre theta0 et theta1\n",
    "        for theta1 in theta1_grid:\n",
    "        Theta0=[theta0,theta1]\n",
    "        trajectories+=[gradient_descent(XYsamp,K,gamma,Theta0)]  #on calcule la trajectoire donnee par la descente de gradient\n",
    "    trajectories=np.array(trajectories)\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c59ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['grid_3c'] = run_gd_on_grid(theta0_grid,theta1_grid,K=200,gamma=0.2)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37df710",
   "metadata": {},
   "source": [
    "## (3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7f0f5",
   "metadata": {},
   "source": [
    "Complete the function below that plots the error vectors for each of the 25 trajectories in a single plot. The error for each trajectory is an array of length 200, with the $k$'th element computed as:\n",
    "\\begin{equation*}\n",
    "e_k := \\sqrt{ (\\hat\\theta_{0,k}-\\theta_0)^2 + (\\hat\\theta_{1,k}-\\theta_1)^2 } \n",
    "\\end{equation*}\n",
    "Here $k\\in[1,...,K]$ is the gradient descent iteration step. Plot all 25 of them on a single plot with the iteration index on the x axis and the logarithm of the error on the y axis. (8 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f374a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(trajectories):\n",
    "    Error_traj_k=[]\n",
    "   \n",
    "    for traj_k in trajectories:\n",
    "        for Theta_k in traj_k:\n",
    "            Error_traj_k += [np.sqrt( (Theta_k[0]-)**2 + (Theta_k[1]-)**2 )]  #calcul de l'erreur\n",
    "           \n",
    "        log_Error_traj_k = np.log(Error_traj_k)  #logarithme\n",
    "       \n",
    "        plt.plot(log_Error_traj_k,marker='o', markersize=4)\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Logarithm of the error')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adc8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig_3d'] = plot_error(result['grid_3c'])\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aeffaf",
   "metadata": {},
   "source": [
    "## (3e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183c16b",
   "metadata": {},
   "source": [
    "The `plot_quiver` function shown below creates an image of the $\\nabla_\\theta J$ as a vector field and returns the figure handle. \n",
    "\n",
    "Your task is to complete `plot_traj`. This function takes the existing figure handle as input (provided by `plot_quiver`) and should overlay it with the 25 trajectories obtained with gradient descent. Each trajectory should be plotted with a thin red line. `plot_traj` should then return the same figure handle. (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quiver():\n",
    "    \n",
    "    gridN = 10\n",
    "    theta0_grid, theta1_grid = make_grid(gridN)\n",
    "    flatgrid = np.reshape([theta0_grid, theta1_grid],(2,gridN**2)).T\n",
    "    UV = np.empty(flatgrid.shape)\n",
    "    for i, (theta0z, theta1z) in enumerate(flatgrid):\n",
    "        UV[i,:] = nablaJ(XYsamp,theta0z, theta1z)\n",
    "    \n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.quiver(flatgrid[:,0], flatgrid[:,1],-UV[:,0],-UV[:,1],scale=30)\n",
    "    \n",
    "    plt.xlabel('theta0',fontsize=15)\n",
    "    plt.ylabel('theta1',fontsize=15)\n",
    "    plt.plot(theta0,theta1,'o',markersize=16)\n",
    "    plt.axis([-1,1,-1,1])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d070a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(fig,trajectories):  \n",
    "    plt.figure(fig)\n",
    "       \n",
    "    # add code here...\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be316da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_traj(plot_quiver(),trajectories)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig_3e'] = plot_traj(plot_quiver(),result['grid_3c'])\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead58e37",
   "metadata": {},
   "source": [
    "## (3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f30ae",
   "metadata": {},
   "source": [
    "Repeat parts (d) and (e) with $\\gamma=0.01$ and $\\gamma=0.7$. (0 pts)\n",
    "Note: This part is not awarded points. It is simply for you to appreciate the effect of the step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "trajectories2 = run_gd_on_grid(theta0_grid,theta1_grid ,K=200,gamma=0.01)\n",
    "result['fig_3fA_phase'] = plot_traj(plot_quiver(),trajectories2)\n",
    "result['fig_3fA_error'] = plot_error(trajectories2)\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15fc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "trajectories3 = run_gd_on_grid(theta0_grid,theta1_grid ,K=200,gamma=0.7)\n",
    "result['fig_3fB_phase'] = plot_traj(plot_quiver(),trajectories3)\n",
    "result['fig_3fB_error'] = plot_error(trajectories3)\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f24ab1",
   "metadata": {},
   "source": [
    "# 4. Additive cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24640461",
   "metadata": {},
   "source": [
    "The deliverable for this part is a single plot is in the $\\theta_0, \\theta_1$ plane. The limits should be from -1 to 1 along both axes, as in previous parts. The plot should have these elements. (10 pts)\n",
    "\n",
    "+ For each sample $n$, draw a thin black line in the parameter space corresponding to $\\ell_n=0$. There should be a total of $N=40$ lines. \n",
    "+ Place a small dot at the intersection of every line. There will be a total of $N(N-1)/2$ such dots. Briefly explain the interpretation of these intersections. \n",
    "+ Plot a large dot at the location of the true parameter values. \n",
    "+ Overylay one of the gradient descent trajectories from part 3.\n",
    "\n",
    "Save the handle of the figure in the variable `fig4`. This will be added to the results dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19835332",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c498e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig4'] = fig4\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4670ba9",
   "metadata": {},
   "source": [
    "# 5. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c68bd1",
   "metadata": {},
   "source": [
    "## 5(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad0f50",
   "metadata": {},
   "source": [
    "(10 pts) Code stochastic gradient descent. Complete the function `SGD` below. This function takes as arguments \n",
    "+ the dataset `XYsamp`, \n",
    "+ the step size $\\gamma$ and \n",
    "+ the number of epochs to run. \n",
    "\n",
    "`SGD` function should\n",
    "\n",
    "+ randomly choose the initial condition with uniform probability from $[-1,1]\\times[-1,1]$\n",
    "+ use batches of size 1,\n",
    "+ draw samples without replacement.\n",
    "\n",
    "The function should return the parameter trajectory. \n",
    "\n",
    "\n",
    "Run SGD with $\\gamma=0.1$ and 10 epochs. Recreate the plot from part 4 but using this SGD trajectory instead of GD. Save the figure handle as `fig5a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ff45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(XYsamp,gamma,epochs):\n",
    "    x = stats.uniform.rvs(loc = -1, scale = 2)\n",
    "    y = stats.uniform.rvs(loc = -1, scale = 2)\n",
    "    for \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895928a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig5a \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig5a = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3902c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig5a'] = fig5a\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce74ae9",
   "metadata": {},
   "source": [
    "## 5(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4ab5c",
   "metadata": {},
   "source": [
    "Make the same plot with $\\gamma=0.01$ and $\\gamma=0.4$. Save the figure handles respectively as `fig5b1` and `fig5b2`. (6 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21882b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5b1 = plt.figure()\n",
    "fig5b2 = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['fig5b1'] = fig5b1\n",
    "result['fig5b2'] = fig5b2\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd92d2",
   "metadata": {},
   "source": [
    "## 5(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbda051",
   "metadata": {},
   "source": [
    "Comment on the pros and cons of SGD with respect to GD. Save your comments in a string called `comment`. (6 pts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a5bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c6dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Reporting. Do not modify.#####\n",
    "result['comment'] = comment\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3c1d9",
   "metadata": {},
   "source": [
    "---\n",
    "## Do not modify below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}.pickle'.format(\"_\".join([str(sid) for sid in result['SIDs']])),'wb') as file:\n",
    "    pickle.dump(result,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
